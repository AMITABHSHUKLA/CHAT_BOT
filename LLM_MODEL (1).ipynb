{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l20h14iCZ0v",
        "outputId": "a0a0f0b2-d7ea-4b21-8502-5cf6f9e5c083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-560m\")"
      ],
      "metadata": {
        "id": "AZPiLsBIC9Ol"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.__class__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CltgtbZ8DE5h",
        "outputId": "65f2b3e8-d76e-4d5b-d57d-79d2fb72adb6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.bloom.modeling_bloom.BloomForCausalLM"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed"
      ],
      "metadata": {
        "id": "X790QAbWDZMn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(11111)"
      ],
      "metadata": {
        "id": "PFt4BtXHDp5-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"what are you doing to night??\""
      ],
      "metadata": {
        "id": "6c9YNfM0EXH_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_token = tokenizer(text,return_tensors = \"pt\").to(0)"
      ],
      "metadata": {
        "id": "TMUieQ6rEhBa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.generate(**input_token, max_length = 200, top_k = 0,temperature = 0.5)"
      ],
      "metadata": {
        "id": "AJgOq8NtE5EQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_lqWk5aGr6j",
        "outputId": "d2d5788f-2205-4f61-9a22-db69d354030c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[160240,   1152,  67067,   4913,   1074,   2040,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603,      5,  23857,   1130,     34,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603,      5,  23857,   1130,     34,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603,      5,  23857,   1130,     34,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603,      5,  23857,   1130,     34,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603,      5,  23857,   1130,     34,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603,      5,  23857,   1130,     34,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603,      5,  23857,   1130,     34,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603,      5,  23857,   1130,     34,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603,      5,  23857,   1130,     34,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603,      5,  23857,   1130,     34,      5,    603,      5,\n",
              "          23857,   1130,     34,      5,    603,      5,  23857,   1130,     34,\n",
              "              5,    603]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = tokenizer.decode(result[0])"
      ],
      "metadata": {
        "id": "vyeAku-kGTdD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfbKSWxWGzuG",
        "outputId": "bf06387e-688a-4878-ed13-4de161034906"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what are you doing to night???\n",
            "I just got back from a trip to the beach. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry. I was so tired and hungry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reply = ans.split(\"\\n\")"
      ],
      "metadata": {
        "id": "-YdNQHRuI_S_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply = ans.split(\".\")"
      ],
      "metadata": {
        "id": "aaEuQUmiO47Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = []\n",
        "for item in reply:\n",
        "  if item in [text,\"\\n\",\"\",\" \"]:\n",
        "    continue\n",
        "  else:\n",
        "    answer.append(item)"
      ],
      "metadata": {
        "id": "QOAuKU9oJGaC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-WvnIMGTECr",
        "outputId": "b281ce7e-da34-40be-d59b-57dbce13f806"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what are you doing to night???\\nI just got back from a trip to the beach', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry', ' I was so tired and hungry']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Chatbot() :\n",
        "\n",
        "  text = input(\"TEXT :- \")\n",
        "  input_token = tokenizer(text,return_tensors = \"pt\").to(0)\n",
        "  result = model.generate(**input_token, max_length = 200, top_k = 0,temperature = 0.5)\n",
        "  ans = tokenizer.decode(result[0])\n",
        "  reply = ans.split(\".\")\n",
        "  \n",
        "  try :\n",
        "    reply = ans.split(\".\")\n",
        "    print(reply[1])\n",
        "\n",
        "  except :\n",
        "    reply = ans.split(\"\\n\")\n",
        "    print(reply[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UhEavCfQHglP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "while True :\n",
        "  Chatbot()\n",
        "  "
      ],
      "metadata": {
        "id": "oftYLGVcJy1l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}